{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#entregas-em-grupo","title":"\u2728Entregas em Grupo\u2728","text":""},{"location":"#sobre","title":"Sobre","text":"<ul> <li>Ana Carolina Frank</li> <li>Luzivania Bonfim</li> <li>Maria Luiza Oliveira</li> <li>Marcela de Martini</li> </ul> Informa\u00e7\u00f5es da Turma <ul> <li>Curso: Ci\u00eancia de Dados</li> <li>Disciplina: Machine Learning</li> <li>Semestre: 4\u00ba Semestre \u2014 2025.2</li> <li>Professor: Humberto Sandmann</li> </ul>"},{"location":"#entregas","title":"Entregas","text":"<p>Abaixo, voc\u00ea pode acompanhar o progresso das atividades:</p> <ul> <li> Projeto 1</li> <li> Projeto 2 </li> </ul>"},{"location":"projeto1/main/","title":"Projeto 1","text":""},{"location":"projeto1/main/#projeto-obesity-classification","title":"Projeto - Obesity Classification","text":"<p>Esse projeto tem como objetivo aplicar t\u00e9cnicas de Machine Learning, abordando \u00c1rvore de Decis\u00e3o, KNN e K-Means, para prever a presen\u00e7a de obesidade a partir de vari\u00e1veis f\u00edsicas.</p> <ul> <li> <p>Fonte: Obesity Classification</p> </li> <li> <p>Formato: 108 observa\u00e7\u00f5es x 7 colunas.</p> </li> <li> <p>Colunas: </p> <ul> <li>ID: Identificador</li> <li>Age: Idade do indiv\u00edduo</li> <li>Gender: Sexo (Male/Female)</li> <li>Height: Altura (Em CM)</li> <li>Weight: Peso (Em KG)</li> <li>BMI: Em portugu\u00eas, IMC. \u00cdndice de massa corporal.</li> <li>Label: Vari\u00e1vel alvo, com 4 classes:<ul> <li><code>Underweight</code> (0)</li> <li><code>Normal Weight</code> (1)</li> <li><code>Overweight</code> (2)</li> <li><code>Obese</code> (3)</li> </ul> </li> </ul> </li> </ul> <p>Observa\u00e7\u00e3o: A coluna <code>ID</code> foi removida das features, identificador n\u00e3o informativo.</p>"},{"location":"projeto1/main/#exploracao-de-dados","title":"Explora\u00e7\u00e3o de Dados","text":"<ul> <li>Distribui\u00e7\u00e3o de classes:</li> </ul> Classe Contagem Underweight 47 Normal Weight 29 Overweight 20 Obese 12 <p>Existe desbalanceamento pronunciado (Underweight \u2248 4\u00d7 Obese).  Isso exige cuidado: usar estratifica\u00e7\u00e3o no split, aplicar t\u00e9cnicas de oversampling (SMOTE) apenas no conjunto de treino ou utilizar <code>class_weight</code> em modelos que aceitam.</p>"},{"location":"projeto1/main/#verificacao-de-bmi","title":"Verifica\u00e7\u00e3o de <code>BMI</code>","text":"<p>Ao recalcular BMI a partir de Height e Weight (assumindo Height em cm, convertido para metros), encontramos inconsist\u00eancia significativa entre a coluna BMI fornecida e o BMI calculado:</p> <ul> <li>105 de 108 linhas (\u2248 97.22%) t\u00eam diferen\u00e7a absoluta |BMI - BMI_calc| &gt; 0.2.</li> </ul> <p>Confirmar a origem e unidade das colunas; recalcular BMI a partir de Height/Weight e usar o BMI recalculado (ou remover a coluna BMI original), pois valores inconsistentes podem introduzir ru\u00eddo severo.</p> Resultado ID Age Gender Height Weight BMI Label 80 60 Female 120 70 23.4 Normal Weight 11 18 Male 175 70 23.4 Normal Weight 5 45 Male 190 100 31.2 Obese 86 13 Male 175 25 10 Underweight 65 36 Male 190 75 24.2 Normal Weight 70 61 Female 120 75 25 Overweight 32 24 Female 160 55 21.2 Normal Weight 48 52 Female 130 75 25 Overweight 98 22 Male 180 20 8.3 Underweight 12 23 Female 160 50 20 Underweight"},{"location":"projeto1/main/#pre-processamento","title":"Pr\u00e9-Processamento","text":"<ul> <li>Remo\u00e7\u00e3o de <code>ID</code></li> <li>Mapeamento da target <code>Label</code> para inteiros:<ul> <li>Underweight: 0</li> <li>Normal: 1</li> <li>Overweight: 2</li> <li>Obese: 3</li> </ul> </li> <li><code>Gender</code> codificado com <code>LabelEncoder</code> (0/1).</li> <li>Convers\u00e3o de vari\u00e1veis categ\u00f3ricas com pd.get_dummies(..., drop_first=True) para modelos que exigem entradas num\u00e9ricas.</li> <li>Para KMeans: aplica\u00e7\u00e3o de <code>StandardScaler</code> antes do PCA/clusteriza\u00e7\u00e3o.</li> </ul> Resultado Age Gender Height Weight BMI Label 60 0 120 70 23.4 1 18 1 175 70 23.4 1 45 1 190 100 31.2 3 13 1 175 25 10 0 36 1 190 75 24.2 1 61 0 120 75 25 2 24 0 160 55 21.2 1 52 0 130 75 25 2 22 1 180 20 8.3 0 23 0 160 50 20 0"},{"location":"projeto1/main/#divisao-de-dados","title":"Divis\u00e3o de dados","text":"<p>Separar 70% para treino e 30% para teste: </p> <p><code>train_test_split(test_size=0.3, random_state=42, stratify=y).</code></p> <p>Treino (70%)</p> Label (num) Contagem 0 (Underweight) 33 1 (Normal Weight) 20 2 (Overweight) 14 3 (Obese) 8 <p>Teste (30%)</p> Label (num) Contagem 0 (Underweight) 14 1 (Normal Weight) 9 2 (Overweight) 6 3 (Obese) 4"},{"location":"projeto1/main/#modelagem-e-resultados","title":"Modelagem e resultados","text":"<p>Configura\u00e7\u00e3o geral: <code>random_state = 42</code>em opera\u00e7\u00f5es determin\u00edsticas; preservamos estratifica\u00e7\u00e3o no split para todas as avalia\u00e7\u00f5es.</p>"},{"location":"projeto1/main/#decision-tree","title":"Decision Tree","text":"<ul> <li>Resultado: Accuracy = 0.9697 (\u2248 96.97%).</li> </ul> Decision TreeCode <p>Accuracy: 0.88  2025-12-07T15:59:43.270088 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ </p> <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom io import StringIO\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\n\n\n\n\ndf = pd.read_csv('https://raw.githubusercontent.com/bligui/Machine-Learning-Projetos/refs/heads/main/base/Obesity%20Classification.csv')\n\n#E\u00e9 a tabela que se refere ao id do individuo\ndf = df.drop(columns=['ID'])\n\n\ndf[\"Label\"] = df[\"Label\"].map({\n    \"Underweight\": 0,\n    \"Normal Weight\": 1,\n    \"Overweight\": 2,\n    \"Obese\": 3\n})\n\nlabel_encoder = LabelEncoder()  \ndf['Gender'] = label_encoder.fit_transform(df['Gender'])\n\nx = df.drop(columns=['Label'])\ny = df['Label']\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42, stratify=y)\n\n# para Criar e treinar o modelo de \u00e1rvore de decis\u00e3o\nclassifier = tree.DecisionTreeClassifier(random_state=42)\nclassifier.fit(x_train, y_train)\n\nplt.figure(figsize=(12,10))\n\n# Avalia\u00e7\u00e3o o modelo, medindo a acuracia\naccuracy = classifier.score(x_test, y_test)\nprint(f\"Accuracy: {accuracy:.2f}\")\ntree.plot_tree(classifier)\n\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\")\nprint(buffer.getvalue())\n</code></pre> <p>Classification report (precision / recall / f1 / support):</p> <ul> <li> <p>Underweight: </p> <ul> <li>precision=1.00, </li> <li>recall=1.00, </li> <li>f1=1.00 (support=14)</li> </ul> </li> <li> <p>Normal: </p> <ul> <li>precision=0.90, </li> <li>recall=1.00, </li> <li>f1\u22480.947 (support=9)</li> </ul> </li> <li> <p>Overweight: </p> <ul> <li>precision=1.00, </li> <li>recall\u22480.833, </li> <li>f1\u22480.909 (support=6)</li> </ul> </li> <li> <p>Obese: </p> <ul> <li>precision=1.00,</li> <li>recall=1.00,</li> <li>f1=1.00 (support=4)</li> </ul> </li> </ul> <p>Interpreta\u00e7\u00e3o: desempenho muito alto no conjunto de teste, aten\u00e7\u00e3o ao overfitting, especialmente com \u00e1rvores n\u00e3o podadas em datasets pequenos. Recomenda-se valida\u00e7\u00e3o com CV e ajuste de hiperpar\u00e2metros (max_depth, min_samples_leaf, ccp_alpha).</p>"},{"location":"projeto1/main/#knn","title":"KNN","text":"<p>Resultado: Accuracy = 0.9394 (\u2248 93.94%). 5\u2011fold CV: m\u00e9dia \u2248 0.879654, desvio \u2248 0.022436.</p> KNNCode <p>Accuracy: 0.94  2025-12-07T15:59:56.781612 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/   Valida\u00e7\u00e3o Cruzada: 0.880 \u00b1 0.022 K=11 Accuracy: 0.879 Matriz de Confus\u00e3o: [[14  0  0  0]  [ 1  7  1  0]  [ 0  0  6  0]  [ 0  0  0  4]] </p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom io import StringIO\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nimport seaborn as sns\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\ndf = pd.read_csv('https://raw.githubusercontent.com/bligui/Machine-Learning-Projetos/refs/heads/main/base/Obesity%20Classification.csv')\ndf = df.drop(columns=['ID'])\n\ndf[\"Label\"] = df[\"Label\"].map({\n    \"Underweight\": 0,\n    \"Normal Weight\": 1,\n    \"Overweight\": 2,\n    \"Obese\": 3\n})\n\nlabel_encoder = LabelEncoder()  \ndf['Gender'] = label_encoder.fit_transform(df['Gender'])\n\nX = df[['Height', 'Weight']]\ny = df['Label']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n\n# Treinamento do KNN\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train, y_train)\n\n# Teste e valida\u00e7\u00e3o\npredictions = knn.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions):.2f}\")\n\n# Mapeamento CORRETO para todas as 4 classes\nlabels_map = {\n    0: \"Underweight\",\n    1: \"Normal Weight\", \n    2: \"Overweight\",\n    3: \"Obese\"\n}\ny_labels = y.map(labels_map)\n\n# Prepara\u00e7\u00e3o para o gr\u00e1fico\nh = 0.02\nx_min, x_max = X.iloc[:, 0].min() - 1, X.iloc[:, 0].max() + 1\ny_min, y_max = X.iloc[:, 1].min() - 1, X.iloc[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n\n# Prevendo classe em cada ponto\nZ = knn.predict(np.c_[xx.ravel(), yy.ravel()])\nZ = Z.reshape(xx.shape)\n\n# Gr\u00e1fico final com todas as 4 classes\npalette = {\n    \"Underweight\": 'blue',\n    \"Normal Weight\": 'green',\n    \"Overweight\": 'orange',\n    \"Obese\": 'red'\n}\n\nplt.figure(figsize=(10, 8))\nplt.contourf(xx, yy, Z, cmap=plt.cm.RdYlGn_r, alpha=0.3)\nsns.scatterplot(x=X.iloc[:, 0], y=X.iloc[:, 1], hue=y_labels, style=y_labels, palette=palette, s=100)\nplt.xlabel(\"Height\")\nplt.ylabel(\"Weight\")\nplt.title(\"KNN Decision Boundary (k=3) - Diagn\u00f3stico de Obesidade\")\nplt.legend(title=\"Diagn\u00f3stico de obesidade\")\n\n# Exibi\u00e7\u00e3o do gr\u00e1fico\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=True)\nprint(buffer.getvalue())\n\n\n\n\n\n\n# 1. Valida\u00e7\u00e3o Cruzada\nfrom sklearn.model_selection import cross_val_score\nscores = cross_val_score(knn, X, y, cv=5)\nprint(f\"Valida\u00e7\u00e3o Cruzada: {scores.mean():.3f} \u00b1 {scores.std():.3f}\")\n\n# 2. Comparar com k maior\nknn_k11 = KNeighborsClassifier(n_neighbors=11)\nknn_k11.fit(X_train, y_train)\nprint(f\"K=11 Accuracy: {accuracy_score(y_test, knn_k11.predict(X_test)):.3f}\")\n\n# 3. Matriz de Confus\u00e3o\nfrom sklearn.metrics import confusion_matrix\nprint(\"Matriz de Confus\u00e3o:\")\nprint(confusion_matrix(y_test, predictions))\n</code></pre> <p>Interpreta\u00e7\u00e3o: KNN com Height &amp; Weight separa bem as classes; performance sens\u00edvel a k e escalonamento. Recomenda-se testar StandardScaler e GridSearchCV para n_neighbors e weights.</p>"},{"location":"projeto1/main/#kmeans","title":"KMeans","text":"<p>PCA (2 componentes):</p> <ul> <li> <p>PC1: 0.5597427 (\u224855.97% da vari\u00e2ncia)</p> </li> <li> <p>PC2: 0.3135229 (\u224831.35% da vari\u00e2ncia)</p> </li> <li> <p>Soma \u2248 0.873266 (\u224887.33%)</p> </li> </ul> <p>Inertia (KMeans):</p> <ul> <li> <p>k = 4 \u2192 inertia = 96.192596</p> </li> <li> <p>k = 5 \u2192 inertia = 68.679993</p> </li> </ul> kmeanscode 2025-12-07T15:59:57.054108 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom io import StringIO\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nimport pandas as pd\n\n# Carregar dataset\ndf = pd.read_csv('https://raw.githubusercontent.com/bligui/Machine-Learning-Projetos/refs/heads/main/base/Obesity%20Classification.csv')\n\n# Features (remover a target e transformar vari\u00e1veis categ\u00f3ricas em dummies)\nX = pd.get_dummies(df.drop(columns=['Label']), drop_first=True)\n\n# Escalar dados\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Redu\u00e7\u00e3o de dimensionalidade PCA\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_scaled)\n\n# KMeans clustering\nkmeans = KMeans(n_clusters=5, init='k-means++', max_iter=100, random_state=42)\nlabels = kmeans.fit_predict(X_pca)\n\n# Adicionar clusters ao DataFrame original\ndf['Cluster'] = labels\n\n# Visualiza\u00e7\u00e3o dos clusters\nplt.figure(figsize=(10, 8))\nplt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels, cmap='viridis', s=50)\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1],\n            c='red', marker='*', s=200, label='Centr\u00f3ides')\nplt.title('Clusters ap\u00f3s redu\u00e7\u00e3o de dimensionalidade (PCA)')\nplt.xlabel('Componente Principal 1')\nplt.ylabel('Componente Principal 2')\nplt.legend()\n\n# Salvar gr\u00e1fico no buffer (para exibir no Markdown)\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=True)\nprint(buffer.getvalue())\n\n# Caso queira ver localmente tamb\u00e9m, descomente:\n# plt.show()\n\n# Tabela de vari\u00e2ncia explicada\nvariancias = pca.explained_variance_ratio_\ntabela_variancia = pd.DataFrame({\n    'Componente Principal': [f'PC{i+1}' for i in range(len(variancias))],\n    'Vari\u00e2ncia Explicada': variancias,\n    'Vari\u00e2ncia Acumulada': np.cumsum(variancias)\n})\n\n# print(tabela_variancia.to_markdown(index=False))\n\n# Vari\u00e2ncia total explicada\n# print(\"\\nVari\u00e2ncia total explicada (2 componentes):\", np.sum(variancias))\n\n# Resultados do KMeans\n# print(\"\\nCentr\u00f3ides finais (no espa\u00e7o PCA):\", kmeans.cluster_centers_)\n# print(\"In\u00e9rcia (WCSS):\", kmeans.inertia_)\n</code></pre> <p>Interpreta\u00e7\u00e3o: os dois primeiros PCs explicam ~87% da vari\u00e2ncia, logo a proje\u00e7\u00e3o 2D \u00e9 representativa. k=5 apresenta menor inertia, mas a escolha final de k deve considerar silhouette score e interpreta\u00e7\u00e3o dos clusters em rela\u00e7\u00e3o \u00e0s classes reais.</p>"},{"location":"projeto1/main/#conclusao","title":"Conclus\u00e3o","text":"<ul> <li>Modelos testados (Decision Tree e KNN) apresentam desempenho elevado no conjunto de teste (\u224897% e \u224894%, respectivamente). Entretanto, o dataset \u00e9 pequeno e possui desbalanceamento e inconsist\u00eancia cr\u00edtica na coluna BMI.</li> </ul>"},{"location":"projeto2/main/","title":"Projeto 2","text":""},{"location":"projeto2/main/#projeto-ii","title":"Projeto II","text":"<p>Este projeto apresenta uma an\u00e1lise de regress\u00e3o aplicada \u00e0 previs\u00e3o de notas de filmes, utilizando diferentes algoritmos de Machine Learning. Ao longo do relat\u00f3rio s\u00e3o abordadas a explora\u00e7\u00e3o e prepara\u00e7\u00e3o dos dados, a implementa\u00e7\u00e3o dos modelos, a avalia\u00e7\u00e3o de desempenho e a compara\u00e7\u00e3o entre os resultados obtidos.</p>"},{"location":"projeto2/main/#sumario","title":"Sum\u00e1rio","text":"<ul> <li>Vis\u00e3o Geral</li> <li>1. Explora\u00e7\u00e3o dos Dados </li> <li>2. Regress\u00e3o Linear</li> <li>3. Implementa\u00e7\u00e3o dos Modelos</li> <li>4. Avalia\u00e7\u00e3o dos Modelos</li> <li>5. Relat\u00f3rio Final</li> <li>6. Poss\u00edveis melhorias</li> </ul>"},{"location":"projeto2/main/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>Objetivo: prever a vari\u00e1vel cont\u00ednua <code>nota</code> a partir de <code>posicao</code> e <code>data</code>.</p> <p>Fluxo do projeto:</p> <ol> <li>Carregar e explorar dados</li> <li>Se poucos registros, gerar dados sint\u00e9ticos realistas</li> <li>Criar features (dias desde in\u00edcio)</li> <li>Treinar pelo menos 3 modelos de regress\u00e3o</li> <li>Avaliar com m\u00e9tricas apropriadas (R\u00b2, RMSE, MAE)</li> <li>Comparar e interpretar resultados</li> </ol>"},{"location":"projeto2/main/#exploracao-de-dados","title":"Explora\u00e7\u00e3o de Dados","text":"<p>O conjunto de dados foi obtido por meio de raspagem do site do IMDB e possui uma estrutura semelhante a uma s\u00e9rie temporal, monitorando o desempenho de 20 filmes ao longo de um m\u00eas, com registros di\u00e1rios de nota e posi\u00e7\u00e3o no ranking. O objetivo desta an\u00e1lise explorat\u00f3ria \u00e9 compreender a estrutura dos dados, avaliar sua qualidade e identificar as rela\u00e7\u00f5es fundamentais entre as vari\u00e1veis, servindo como base s\u00f3lida para o desenvolvimento de modelos de Machine Learning.</p> <p>O dataset \u00e9 composto por 5 colunas(id, id_filme, nota, posicao e data) e 600 observa\u00e7\u00f5es.</p> TabelaCode id id_filme nota posicao data 111 12 4.6 11 2025-11-06 420 5 0.4 20 2025-11-21 566 4 8.3 6 2025-11-29 78 20 2.4 18 2025-11-04 182 7 7.7 2 2025-11-10 285 17 6.8 5 2025-11-15 11 9 5.6 11 2025-11-01 470 9 5.6 10 2025-11-24 79 14 2.2 19 2025-11-04 350 19 6 10 2025-11-18 <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom io import StringIO\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nfrom tabulate import tabulate  \n\n\n#carregamento da base\ndf = pd.read_csv('https://raw.githubusercontent.com/bligui/Machine-Learning-Projetos/refs/heads/main/docs/projeto2/RankingT.csv')\nprint(df.sample(n=10, random_state=42).to_markdown(index=False))\n</code></pre> <p>A m\u00e9dia das notas foi de 5,58, indicando que os filmes, em geral, possuem uma avalia\u00e7\u00e3o intermedi\u00e1ria. A mediana apresentou valor pr\u00f3ximo \u00e0 m\u00e9dia, o que sugere uma distribui\u00e7\u00e3o relativamente sim\u00e9trica. </p> <p></p> <ul> <li>O histograma mostra que a maior concentra\u00e7\u00e3o de dados est\u00e1 entre 4 e 6, indicando que a maioria dos filmes recebe notas nessa faixa.</li> </ul>"},{"location":"projeto2/main/#regressao-linear","title":"Regress\u00e3o Linear:","text":"Cod\u00edgo Regress\u00e3o  <pre><code>import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\nfrom sklearn.metrics import mean_squared_error, r2_score, confusion_matrix, classification_report\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\n\n\ndf = pd.read_csv(\"RankingT.csv\")\n\ndf['data'] = pd.to_datetime(df['data'])\ndata_inicial = df['data'].min()\ndf['dias_desde_inicio'] = (df['data'] - data_inicial).dt.days\n\ny=df['nota']\nX=df[['posicao']]\n\n#treino e teste\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\nmodelo = LinearRegression()\nmodelo.fit(X, y)\n\n# Previs\u00f5es separadas para treino e teste\ny_pred_train = modelo.predict(X_train)\ny_pred_test = modelo.predict(X_test)\n\ncoeficiente = modelo.coef_[0]\n\nprint(\"\\n&gt;&gt; RESULTADOS REGRESS\u00c3O LINEAR - TREINO:\")\nprint(f\"R\u00b2: {r2_score(y_train, y_pred_train):.3f}\")\nprint(f\"RMSE: {np.sqrt(mean_squared_error(y_train, y_pred_train)):.2f}\")\nprint(f\"MAE: {mean_absolute_error(y_train, y_pred_train):.2f}\")\n\nprint(\"\\n&gt;&gt; RESULTADOS REGRESS\u00c3O LINEAR - TESTE:\")\nprint(f\"R\u00b2: {r2_score(y_test, y_pred_test):.3f}\")\nprint(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_test)):.2f}\")\nprint(f\"MAE: {mean_absolute_error(y_test, y_pred_test):.2f}\")\n</code></pre> <p>RESULTADOS REGRESS\u00c3O LINEAR - TREINO:</p> <p>R\u00b2: 0.889,  RMSE: 0.82,  MAE: 0.67</p> <p>RESULTADOS REGRESS\u00c3O LINEAR - TESTE:</p> <p>R\u00b2: 0.883, RMSE: 0.82,  MAE: 0.67</p> <p>O valor de R\u00b2 indica que o modelo explica cerca de 88% da varia\u00e7\u00e3o da nota dos filmes. Os erros (RMSE e MAE) s\u00e3o relativamente baixos, e a proximidade entre os resultados de treino e teste indica aus\u00eancia de overfitting significativo.</p> <p></p>"},{"location":"projeto2/main/#implementacao-dos-modelos","title":"Implementa\u00e7\u00e3o dos Modelos","text":"<p>Os modelos escolhidos foram:</p> <ol> <li>Decision tree</li> <li>KNN</li> <li>Random Forest</li> </ol> Random ForestKNNDecision tree <pre><code>import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n\n# Carregar dados\ndf = pd.read_csv(\n    'https://raw.githubusercontent.com/bligui/Machine-Learning-Projetos/refs/heads/main/docs/projeto2/RankingT.csv'\n)\n\n# Converter data\ndf['data'] = pd.to_datetime(df['data'])\n\n# Remover ID\ndf = df.drop(columns=['id'])\n\n# Definir X e y\nX = df[['posicao']]\ny = df['nota']\n\n# Divis\u00e3o treino/teste\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.3, random_state=42\n)\n\n# Criar e treinar modelo\nmodelo = RandomForestRegressor(\n    n_estimators=200,\n    random_state=42\n)\n\nmodelo.fit(X_train, y_train)\n\n# Previs\u00f5es\ny_pred = modelo.predict(X_test)\n\n# M\u00e9tricas\nr2 = r2_score(y_test, y_pred)\nrmse = np.sqrt(mean_squared_error(y_test, y_pred))\nmae = mean_absolute_error(y_test, y_pred)\n\n# Resultados\nprint(\"\\n===== RANDOM FOREST REGRESS\u00c3O =====\")\nprint(f\"R\u00b2: {r2:.4f}\")\nprint(f\"RMSE: {rmse:.4f}\")\nprint(f\"MAE: {mae:.4f}\")\n\n# Exemplo de previs\u00e3o\nnova_posicao = np.array([[5]])\nnota_prevista = modelo.predict(nova_posicao)\n\nprint(\"\\nPrevis\u00e3o de Nota (posi\u00e7\u00e3o 5):\", round(nota_prevista[0], 2))\n</code></pre> <pre><code>import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n\n# Carregar dados\ndf = pd.read_csv(\n    'https://raw.githubusercontent.com/bligui/Machine-Learning-Projetos/refs/heads/main/docs/projeto2/RankingT.csv'\n)\n\n# Converter data\ndf['data'] = pd.to_datetime(df['data'])\n\n# Remover ID\ndf = df.drop(columns=['id'])\n\n# Definir X e y\nX = df[['posicao']]\ny = df['nota']\n\n# Divis\u00e3o treino/teste\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.3, random_state=42\n)\n\n# Criar e treinar modelo\nmodelo = KNeighborsRegressor(n_neighbors=5)\nmodelo.fit(X_train, y_train)\n\n# Previs\u00f5es\ny_pred = modelo.predict(X_test)\n\n# M\u00e9tricas\nr2 = r2_score(y_test, y_pred)\nrmse = np.sqrt(mean_squared_error(y_test, y_pred))\nmae = mean_absolute_error(y_test, y_pred)\n\n# Resultados\nprint(\"\\n===== KNN REGRESS\u00c3O =====\")\nprint(f\"R\u00b2: {r2:.4f}\")\nprint(f\"RMSE: {rmse:.4f}\")\nprint(f\"MAE: {mae:.4f}\")\n\n# Exemplo de previs\u00e3o\nnova_posicao = np.array([[5]])\nnota_prevista = modelo.predict(nova_posicao)\n\nprint(\"\\nPrevis\u00e3o de Nota (posi\u00e7\u00e3o 5):\", round(nota_prevista[0], 2))\n</code></pre> <pre><code>import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import r2_score\n\n# Carregar dados\ndf = pd.read_csv('https://raw.githubusercontent.com/bligui/Machine-Learning-Projetos/refs/heads/main/docs/projeto2/RankingT.csv')\n\n# Converter data\ndf['data'] = pd.to_datetime(df['data'])\ndata_inicial = df['data'].min()\ndf['dias_desde_inicio'] = (df['data'] - data_inicial).dt.days\n\n# Remover ID (n\u00e3o ajuda no modelo)\ndf = df.drop(columns=['id'])\n\n# Definir X e Y\nX = df[['posicao', 'dias_desde_inicio']]\ny = df['nota']\n\n# Divis\u00e3o treino e teste\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.3, random_state=42\n)\n\n# Criar modelo\nmodelo = DecisionTreeRegressor(random_state=42)\nmodelo.fit(X_train, y_train)\n\n# Avalia\u00e7\u00e3o\ny_pred = modelo.predict(X_test)\nr2 = r2_score(y_test, y_pred)\n\nprint(\"R\u00b2 (\u00c1rvore de Decis\u00e3o):\", round(r2, 4))\n</code></pre>"},{"location":"projeto2/main/#avaliacao-dos-modelos","title":"Avalia\u00e7\u00e3o dos Modelos","text":"<p>Tabela de Compara\u00e7\u00e3o de Resultados </p> Modelo R\u00b2 RMSE MAE Regress\u00e3o Linear Simples 0.8830 0.820 0.670 \u00c1rvore de Decis\u00e3o 0.8989 0.759 0.588 KNN 0.8816 0.821 0.625 Random Forest 0.8997 0.756 0.586"},{"location":"projeto2/main/#regressao-linear-simples","title":"Regress\u00e3o Linear Simples:","text":"<p>A regress\u00e3o linear simples apresentou um R\u00b2 de 0.883, o que indica que aproximadamente 88,3% da varia\u00e7\u00e3o da nota \u00e9 explicada pela vari\u00e1vel posi\u00e7\u00e3o. Apesar de apresentar um bom desempenho, esse modelo assume uma rela\u00e7\u00e3o linear entre as vari\u00e1veis, o que pode limitar sua capacidade de capturar padr\u00f5es mais complexos ou n\u00e3o lineares presentes nos dados.</p> <p>Seu RMSE de 0.82 e MAE de 0.67 mostram que, em m\u00e9dia, o erro de previs\u00e3o est\u00e1 em torno de 0.6 a 0.8 pontos na nota.</p> <p>\u00c9 um bom modelo base, mas possui limita\u00e7\u00e3o em problemas com maior complexidade.</p>"},{"location":"projeto2/main/#arvore-de-decisao","title":"\u00c1rvore de Decis\u00e3o:","text":"<p>A \u00c1rvore de Decis\u00e3o apresentou um R\u00b2 de 0.8989, superior ao da regress\u00e3o linear simples, indicando que o modelo consegue explicar cerca de 89,9% da varia\u00e7\u00e3o da nota.</p> <p>Este modelo \u00e9 capaz de capturar padr\u00f5es n\u00e3o lineares, pois ele divide o conjunto de dados em regi\u00f5es, criando regras de decis\u00e3o com base nos valores de posi\u00e7\u00e3o.</p> <p>O RMSE (0.7592) e o MAE (0.5878) s\u00e3o menores que os do modelo linear, indicando maior precis\u00e3o na previs\u00e3o.</p> <p>Isso mostra que a rela\u00e7\u00e3o entre posi\u00e7\u00e3o e nota n\u00e3o \u00e9 puramente linear, e que a \u00e1rvore consegue se adaptar melhor aos dados.</p>"},{"location":"projeto2/main/#k-nearest-neighbors-knn","title":"K-Nearest Neighbors (KNN):","text":"<p>O modelo KNN apresentou um R\u00b2 de 0.8816, valor muito pr\u00f3ximo ao da regress\u00e3o linear. Isso indica que ele explica cerca de 88,1% da varia\u00e7\u00e3o da nota, por\u00e9m com desempenho ligeiramente inferior \u00e0 \u00c1rvore e ao Random Forest.</p> <p>Seu RMSE (0.8213) e MAE (0.6250) foram maiores do que os da \u00c1rvore e do Random Forest, mostrando que ele comete erros um pouco maiores na previs\u00e3o.</p> <p>Isso pode estar relacionado ao fato de o KNN ser altamente sens\u00edvel aos dados pr\u00f3ximos e \u00e0 forma como a dist\u00e2ncia entre eles \u00e9 calculada.</p> <p>Apesar disso, ele ainda apresenta um bom desempenho geral.</p>"},{"location":"projeto2/main/#relatorio-final","title":"Relat\u00f3rio Final","text":"<p>Ap\u00f3s a implementa\u00e7\u00e3o e avalia\u00e7\u00e3o dos quatro modelos de regress\u00e3o, foi poss\u00edvel observar que o Random Forest apresentou o melhor desempenho geral, obtendo o maior valor de R\u00b2 (0.8997) e os menores valores de RMSE (0.7562) e MAE (0.5857).</p> <p>Isso indica que o modelo \u00e9 capaz de explicar quase 90% da varia\u00e7\u00e3o das notas, al\u00e9m de apresentar o menor erro m\u00e9dio nas previs\u00f5es.</p> <p>A \u00c1rvore de Decis\u00e3o tamb\u00e9m apresentou um bom desempenho, superando a regress\u00e3o linear simples, o que refor\u00e7a a exist\u00eancia de rela\u00e7\u00f5es n\u00e3o lineares entre a posi\u00e7\u00e3o no ranking e a nota dos filmes.</p> <p>O KNN, embora eficiente, mostrou resultados ligeiramente inferiores aos dois modelos baseados em \u00e1rvores.</p> <p>Dessa forma, o Random Forest foi escolhido como o modelo mais adequado para a previs\u00e3o da nota dos filmes neste projeto.</p>"},{"location":"projeto2/main/#possiveis-melhorias-futuras","title":"Poss\u00edveis Melhorias Futuras","text":"<p>Como melhoria futura, pode ser realizada a inclus\u00e3o de novas vari\u00e1veis, como g\u00eanero do filme, n\u00famero de votos, or\u00e7amento e popularidade, para enriquecer o conjunto de dados.Tamb\u00e9m \u00e9 recomendada a otimiza\u00e7\u00e3o dos hiperpar\u00e2metros dos modelos, especialmente do Random Forest e do KNN. Al\u00e9m disso, a amplia\u00e7\u00e3o do per\u00edodo de coleta de dados pode tornar o modelo mais robusto e reduzir poss\u00edveis vieses temporais. Por fim, podem ser testados algoritmos mais avan\u00e7ados, como Gradient Boosting e Redes Neurais no futuro.</p>"}]}